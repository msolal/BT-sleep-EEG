{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"plot_sleep_staging_braindecode.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"BUETdmQXAC5i","executionInfo":{"status":"ok","timestamp":1610380469652,"user_tz":-60,"elapsed":677,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}}},"source":["%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8swj8x-VAC5p"},"source":["\n","# Sleep staging on the Sleep Physionet dataset\n","\n","This tutorial shows how to train and test a sleep staging neural network with\n","Braindecode. We follow the approach of [1]_ on the openly accessible Sleep\n","Physionet dataset [1]_ [2]_.\n","\n","## References\n",".. [1] Chambon, S., Galtier, M., Arnal, P., Wainrib, G. and Gramfort, A.\n","      (2018)A Deep Learning Architecture for Temporal Sleep Stage\n","      Classification Using Multivariate and Multimodal Time Series.\n","      IEEE Trans. on Neural Systems and Rehabilitation Engineering 26:\n","      (758-769)\n","\n",".. [2] B Kemp, AH Zwinderman, B Tuk, HAC Kamphuisen, JJL Oberyé. Analysis of\n","       a sleep-dependent neuronal feedback loop: the slow-wave\n","       microcontinuity of the EEG. IEEE-BME 47(9):1185-1194 (2000).\n","\n",".. [3] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh,\n","       Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000)\n","       PhysioBank, PhysioToolkit, and PhysioNet: Components of a New\n","       Research Resource for Complex Physiologic Signals.\n","       Circulation 101(23):e215-e220\n"]},{"cell_type":"code","metadata":{"id":"NEZypGDGAC5q","executionInfo":{"status":"ok","timestamp":1610380471486,"user_tz":-60,"elapsed":1055,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}}},"source":["# Authors: Hubert Banville <hubert.jbanville@gmail.com>\n","#\n","# License: BSD (3-clause)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWydEGNNBcwG","executionInfo":{"status":"ok","timestamp":1610380478942,"user_tz":-60,"elapsed":7790,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}},"outputId":"d1ca6202-034b-4bbb-8c01-465c66f70ad2"},"source":["!pip install mne\n","!pip install -U https://github.com/braindecode/braindecode/archive/master.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.22.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.19.4)\n","Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n","Collecting https://github.com/braindecode/braindecode/archive/master.zip\n","  Using cached https://github.com/braindecode/braindecode/archive/master.zip\n","Requirement already satisfied, skipping upgrade: mne in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (0.22.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (1.19.4)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (1.1.5)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (1.4.1)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (3.2.2)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (2.10.0)\n","Requirement already satisfied, skipping upgrade: skorch in /usr/local/lib/python3.6/dist-packages (from Braindecode==0.5) (0.9.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->Braindecode==0.5) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->Braindecode==0.5) (2018.9)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->Braindecode==0.5) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->Braindecode==0.5) (2.4.7)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->Braindecode==0.5) (1.3.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->Braindecode==0.5) (1.15.0)\n","Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch->Braindecode==0.5) (0.8.7)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch->Braindecode==0.5) (4.41.1)\n","Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch->Braindecode==0.5) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch->Braindecode==0.5) (1.0.0)\n","Building wheels for collected packages: Braindecode\n","  Building wheel for Braindecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Braindecode: filename=Braindecode-0.5-cp36-none-any.whl size=93077 sha256=4b77459893745aac529b7f864c51b22a8c5653938c8b91ac2c0e2a0a192913a6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wnq1gpun/wheels/1b/0e/66/cd3db19ce11758437bc31b93aa1327d7a1123b66333af66a12\n","Successfully built Braindecode\n","Installing collected packages: Braindecode\n","  Found existing installation: Braindecode 0.5\n","    Uninstalling Braindecode-0.5:\n","      Successfully uninstalled Braindecode-0.5\n","Successfully installed Braindecode-0.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wzak1Wb-AC5r"},"source":["## Loading and preprocessing the dataset\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u7l_Y_ArAC5s"},"source":["### Loading\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MuLKgwbGAC5s"},"source":["First, we load the data using the\n",":class:`braindecode.datasets.sleep_physionet.SleepPhysionet` class. We load\n","two recordings from two different individuals: we will use the first one to\n","train our network and the second one to evaluate performance (as in the `MNE`_\n","sleep staging example).\n","\n","\n","<div class=\"alert alert-info\"><h4>Note</h4><p>To load your own datasets either via MNE or from\n","   preprocessed X/y numpy arrays, see the `MNE Dataset\n","   Tutorial <./plot_mne_dataset_example.html>`__ and the `Numpy Dataset\n","   Tutorial <./plot_custom_dataset_example.html>`__.</p></div>\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMi1oV3qJbC6","executionInfo":{"status":"ok","timestamp":1610380485403,"user_tz":-60,"elapsed":2759,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}},"outputId":"c1003edb-b1bb-4ec3-c3a4-24367021dbc4"},"source":["import braindecode\n","braindecode"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'braindecode' from '/usr/local/lib/python3.6/dist-packages/braindecode/__init__.py'>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"goH_mQ49JZmx","executionInfo":{"status":"ok","timestamp":1610380386069,"user_tz":-60,"elapsed":737,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}},"outputId":"b7793892-a8de-4ca5-b415-92d0526cd89b"},"source":["%ls /usr/local/lib/python3.6/dist-packages/braindecode/datasets/"],"execution_count":9,"outputs":[{"output_type":"stream","text":["base.py  bbci.py  __init__.py  mne.py  moabb.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/  tuh.py  xy.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhlgQWhIAC5t","executionInfo":{"status":"ok","timestamp":1610380496186,"user_tz":-60,"elapsed":1037,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}},"outputId":"360eea5d-fbf6-4f37-9fe1-b2f46eaba824"},"source":["from braindecode.datasets.sleep_physionet import SleepPhysionet\n","dataset = SleepPhysionet(\n","    subject_ids=[0, 1], recording_ids=[1], crop_wake_mins=30)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using default location ~/mne_data for PHYSIONET_SLEEP...\n","Extracting EDF parameters from /root/mne_data/physionet-sleep-data/SC4001E0-PSG.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Extracting EDF parameters from /root/mne_data/physionet-sleep-data/SC4011E0-PSG.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3-ymXOtaAC5v"},"source":["### Preprocessing\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PdOu4OE0AC5v"},"source":["Next, we preprocess the raw data. We apply convert the data to microvolts and\n","apply a lowpass filter. We omit the downsampling step of [1]_ as the Sleep\n","Physionet data is already sampled at a lower 100 Hz.\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338},"id":"O9CPskJuAC5w","executionInfo":{"status":"error","timestamp":1610379377936,"user_tz":-60,"elapsed":721,"user":{"displayName":"MaÃ«lys SOLAL","photoUrl":"","userId":"18178993830273387352"}},"outputId":"3bc8b07b-626c-4695-b760-f4ce9ddf55b4"},"source":["from braindecode.datautil.preprocess import (\n","    MNEPreproc, NumpyPreproc, preprocess)\n","\n","high_cut_hz = 30\n","\n","preprocessors = [\n","    # convert from volt to microvolt, directly modifying the numpy array\n","    NumpyPreproc(fn=lambda x: x * 1e6),\n","    # bandpass filter\n","    MNEPreproc(fn='filter', l_freq=None, h_freq=high_cut_hz),\n","]\n","\n","# Transform the data\n","preprocess(dataset, preprocessors)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-3a5dedb72a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Transform the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/braindecode/datautil/preprocess.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(concat_ds, preprocessors)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \"Expect preprocessor object to have apply method\")\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcat_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'datasets'"]}]},{"cell_type":"markdown","metadata":{"id":"lsbM0GkIAC5x"},"source":["### Extract windows\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ULsp92c1AC5y"},"source":["We extract 30-s windows to be used in the classification task.\n","\n"]},{"cell_type":"code","metadata":{"id":"hdYR0umxAC5z"},"source":["from braindecode.datautil.windowers import create_windows_from_events\n","\n","\n","mapping = {  # We merge stages 3 and 4 following AASM standards.\n","    'Sleep stage W': 0,\n","    'Sleep stage 1': 1,\n","    'Sleep stage 2': 2,\n","    'Sleep stage 3': 3,\n","    'Sleep stage 4': 3,\n","    'Sleep stage R': 4\n","}\n","\n","window_size_s = 30\n","sfreq = 100\n","window_size_samples = window_size_s * sfreq\n","\n","windows_dataset = create_windows_from_events(\n","    dataset, trial_start_offset_samples=0, trial_stop_offset_samples=0,\n","    window_size_samples=window_size_samples,\n","    window_stride_samples=window_size_samples, preload=True, mapping=mapping)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o4d3oyRQAC5z"},"source":["### Window preprocessing\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5wEorTH8AC5z"},"source":["We also preprocess the windows by applying channel-wise z-score normalization\n","in each window.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"feo5EhhLAC5z"},"source":["from braindecode.datautil.preprocess import zscore\n","\n","preprocess(windows_dataset, [MNEPreproc(fn=zscore)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCotuEuIAC50"},"source":["### Split dataset into train and valid\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sAIxGEWYAC50"},"source":["We can easily split the dataset using additional info stored in the\n","`description` attribute of :class:`braindecode.datasets.BaseDataset`,\n","in this case using the ``subject`` column. Here, we split the examples per subject.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tDHJ4_tTAC51"},"source":["splitted = windows_dataset.split('subject')\n","train_set = splitted['0']\n","valid_set = splitted['1']\n","\n","# Print number of examples per class\n","print(train_set.datasets[0].windows)\n","print(valid_set.datasets[0].windows)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ck9ccVRtAC51"},"source":["## Create model\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"p8HlESITAC51"},"source":["We can now create the deep learning model. In this tutorial, we use the sleep\n","staging architecture introduced in [1]_, which is a four-layer convolutional\n","neural network.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"1lh7NR8gAC51"},"source":["import torch\n","from braindecode.util import set_random_seeds\n","from braindecode.models import SleepStagerChambon2018\n","\n","cuda = torch.cuda.is_available()  # check if GPU is available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if cuda:\n","    torch.backends.cudnn.benchmark = True\n","# Set random seed to be able to reproduce results\n","set_random_seeds(seed=87, cuda=cuda)\n","\n","n_classes = 5\n","# Extract number of channels and time steps from dataset\n","n_channels = train_set[0][0].shape[0]\n","input_size_samples = train_set[0][0].shape[1]\n","\n","model = SleepStagerChambon2018(\n","    n_channels,\n","    sfreq,\n","    n_classes=n_classes,\n","    input_size_s=input_size_samples / sfreq\n",")\n","\n","# Send model to GPU\n","if cuda:\n","    model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_gBB5QwQAC52"},"source":["## Training\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4jTI9nxHAC52"},"source":["We can now train our network. :class:`braindecode.EEGClassifier` is a\n","braindecode object that is responsible for managing the training of neural\n","networks. It inherits from :class:`skorch.NeuralNetClassifier`, so the\n","training logic is the same as in\n","`Skorch <https://skorch.readthedocs.io/en/stable/>`__.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YdSqntb5AC52"},"source":["**Note**: We use different hyperparameters from [1]_, as\n","these hyperparameters were optimized on a different dataset (MASS SS3) and\n","with a different number of recordings. Generally speaking, it is\n","recommended to perform hyperparameter optimization if reusing this code on\n","a different dataset or with more recordings.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"hCRdJmUzAC53"},"source":["from skorch.helper import predefined_split\n","from skorch.callbacks import EpochScoring\n","from braindecode import EEGClassifier\n","\n","lr = 5e-4\n","batch_size = 16\n","n_epochs = 5\n","\n","train_bal_acc = EpochScoring(\n","    scoring='balanced_accuracy', on_train=True, name='train_bal_acc',\n","    lower_is_better=False)\n","valid_bal_acc = EpochScoring(\n","    scoring='balanced_accuracy', on_train=False, name='valid_bal_acc',\n","    lower_is_better=False)\n","callbacks = [('train_bal_acc', train_bal_acc),\n","             ('valid_bal_acc', valid_bal_acc)]\n","\n","clf = EEGClassifier(\n","    model,\n","    criterion=torch.nn.CrossEntropyLoss,\n","    optimizer=torch.optim.Adam,\n","    train_split=predefined_split(valid_set),  # using valid_set for validation\n","    optimizer__lr=lr,\n","    batch_size=batch_size,\n","    callbacks=callbacks,\n","    device=device\n",")\n","# Model training for a specified number of epochs. `y` is None as it is already\n","# supplied in the dataset.\n","clf.fit(train_set, y=None, epochs=n_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJ5ZUkmnAC54"},"source":["## Plot results\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tsqrqYP0AC54"},"source":["We use the history stored by Skorch during training to plot the performance of\n","the model throughout training. Specifically, we plot the loss and the balanced\n","misclassification rate (1 - balanced accuracy) for the training and validation\n","sets.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"O8pdDGmZAC54"},"source":["import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","import pandas as pd\n","\n","# Extract loss and balanced accuracy values for plotting from history object\n","df = pd.DataFrame(clf.history.to_list())\n","df[['train_mis_clf', 'valid_mis_clf']] = 100 - df[\n","    ['train_bal_acc', 'valid_bal_acc']] * 100\n","\n","# get percent of misclass for better visual comparison to loss\n","plt.style.use('seaborn-talk')\n","fig, ax1 = plt.subplots(figsize=(8, 3))\n","df.loc[:, ['train_loss', 'valid_loss']].plot(\n","    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False,\n","    fontsize=14)\n","\n","ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n","ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","\n","df.loc[:, ['train_mis_clf', 'valid_mis_clf']].plot(\n","    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\n","ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n","ax2.set_ylabel('Balanced misclassification rate [%]', color='tab:red',\n","               fontsize=14)\n","ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n","ax1.set_xlabel('Epoch', fontsize=14)\n","\n","# where some data has already been plotted to ax\n","handles = []\n","handles.append(\n","    Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n","handles.append(\n","    Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n","plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JgvbQYtBAC54"},"source":["Finally, we also display the confusion matrix and classification report:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"J7PJfzEaAC55"},"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","y_true = valid_set.datasets[0].windows.metadata['target'].values\n","y_pred = clf.predict(valid_set)\n","\n","print(confusion_matrix(y_true, y_pred))\n","\n","print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3hwnOcOAC55"},"source":["Our model was able to perform reasonably well given the low amount of data\n","available, reaching a balanced accuracy of around 55% in a 5-class\n","classification task (chance-level = 20%) on held-out data.\n","\n","To further improve performance, more recordings can be included in the\n","training set, and various modifications can be made to the model (e.g.,\n","aggregating the representation of multiple consecutive windows [1]_).\n","\n","\n"]}]}